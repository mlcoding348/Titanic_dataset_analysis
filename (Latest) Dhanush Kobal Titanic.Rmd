---
title: "R Notebook"
output: html_notebook
---

<font size="+3">Introduction</font>

<p>Today we will be analyzing the titanic dataset. We will use various ML models, different cross        validation(CV) tools, and feature selection to see which models gives us the best prediction.
This is a kaggle competition.</p>

```{r, echo = FALSE}
rm(list=ls())
```

```{r, echo=FALSE}
# uploading libraries
library(mlr)
library(tidyverse)
library(ggplot2)
library(parallel)
library(parallelMap)
library(hciR)
library(FSelector)
library(FSelectorRcpp)
library(ltm)
```

```{r, echo=FALSE}
library(readr)
train.kaggle <- read_csv("/Users/dhanushkobal/Desktop/2021\ Projects/Kaggle/titanic/train.csv")
train.kaggle$Type.of.data<-as.factor(rep("Train.data", nrow(train.kaggle)))

test.kaggle <- read_csv("/Users/dhanushkobal/Desktop/2021\ Projects/Kaggle/titanic/test.csv")
test.kaggle$Type.of.data<-as.factor(rep("Test.data", nrow(test.kaggle)))

answer.key<- read_csv("/Users/dhanushkobal/Desktop/2021\ Projects/Kaggle/titanic/Answer.key.csv")
real.values<-answer.key$Survived

train.kaggle<-as_tibble(train.kaggle)
test.kaggle<-as_tibble(test.kaggle)

combined.data<-mutate(bind_rows(train.kaggle , test.kaggle)) # combining train and test data
head(combined.data)
```

<font size="+3">Data preprocessing</font>
<p>Our first step is to modify the varibales to their repsective categories: numeric, categorical, and then we will assess the missing values</p>

```{r, echo=FALSE}
combined.data<- combined.data %>% mutate_at(c("Survived","Pclass" ,"Sex", "Embarked", "Cabin"), as.factor)
```

<p>Now we will assess missing values in our dataset</p>

```{r, echo=FALSE}
cbind(apply(is.na(combined.data),2,sum))
```

<p>These are the missing values we are able to find. ***Age and Cabin*** has the most missing values and ***Fare and Embarked*** has the least missing values</p>

<p>We will try to perform ***EDA*** and see if we can get any insights on how to impute these missing values</p>

<font size="+3">EDA</font>
<font size="+2"><li>EDA Analysis 1: Age</li></font>

```{r, echo=FALSE}
eda.data<-train.kaggle %>% dplyr::select(-c( PassengerId, Type.of.data))
```

***Histogram of age***

```{r, echo=FALSE}
ggplot(data = combined.data, aes(x=Age)) + geom_histogram() + ggtitle("Histogram of age")
```

<p>We see that age is rouhgly normally distributed</p>

-----

<p>We will now see how ***Age*** correlates with the categogical varibales</p>

```{r, echo=FALSE}
ggplot(data=gather(eda.data, key = "Variable", value = "Value", -c(Age,Fare, Name, Ticket, Cabin)), aes(Value, Age)) +facet_wrap(~ Variable, scale = "free_x") +geom_boxplot()
```

<p>From the looks of this, there seem to be some pattern with Age and Pclass, so we will take a further analysis into this. We are not dealing with ***Parch and SibSp*** just yet since they both seem to be correlated with each other</p>
-----

<p>We will explore more with ***Age and Pclass***</p>

```{r, echo=FALSE}
ggplot(data = eda.data , aes(x=factor(Pclass), y=Age)) + geom_boxplot() + facet_wrap(~Sex)
```

<p>From the looks of this, we can impute ***Medain*** values for the age based on Sex and Pclass</p>

```{r, echo=FALSE}
age.missing.value<-rep(1, length(eda.data$Age))
age.missing.value[which(is.na(eda.data$Age))]<-0
eda.data$Age.missing.value<-age.missing.value
eda.data$Age.missing.value<-as.factor(eda.data$Age.missing.value)

age.missing.value<-rep(1, length(combined.data$Age))
age.missing.value[which(is.na(combined.data$Age))]<-0
combined.data$Age.missing.value<-age.missing.value
combined.data$Age.missing.value<-as.factor(combined.data$Age.missing.value)
```

```{r, echo=FALSE}
a<-eda.data %>% group_by(Pclass, Sex) %>% summarise( Age = median(Age, na.rm = TRUE))
b<-full_join(eda.data %>% filter(is.na(Age)), a , by = c('Pclass', 'Sex'))$Age.y
eda.data$Age[which(is.na(eda.data$Age))]<-b


a<-combined.data %>% group_by(Pclass, Sex) %>% summarise( Age = median(Age, na.rm = TRUE))
b<-full_join(combined.data %>% filter(is.na(Age)), a , by = c('Pclass', 'Sex'))$Age.y
combined.data$Age[which(is.na(combined.data$Age))]<-b
```

***Updated histogram for Age***
```{r, echo=FALSE}
ggplot(data = combined.data, aes(x=Age)) + geom_histogram() + ggtitle("Imputed histogram for Age")
```

<font size="+2"><li>EDA Analysis 2: Pclass</li></font>

<p>We will first see the realtionship between ***Pclass and Embarked***</p>

```{r, echo=FALSE}
barplot(table(as.factor(eda.data$Pclass), eda.data$Embarked), beside = TRUE, legend.text = TRUE, 
        main= "Relationship between Pclass and Embarked")
eda.data$Pclass.Embarked.relationship<-as.factor(ifelse(eda.data$Pclass==1, "c", "s"))

combined.data$Pclass.Embarked.relationship<-as.factor(ifelse(combined.data$Pclass==1, "c", "s"))
```


<p>From the analysis, we can create a new factor named ***Pclass.Embarked.relationship*** (look at code)</p>

<p>We will take ***SibSp and Parch*** and add them up and call it ***Family.size.numeric ***</p>
```{r, echo=FALSE}
combined.data<-mutate(combined.data, Family.size.numeric = SibSp+Parch+1)
eda.data<-mutate(eda.data, Family.size.numeric = SibSp+Parch+1)
```

```{r, echo=FALSE}
barplot(table(as.factor(eda.data$Pclass), eda.data$Family.size.numeric), beside = TRUE, legend.text = TRUE, 
        main = "Relationship between Fam sie and Pclass")

eda.data$famsize.pclass.relationship<-as.factor(ifelse(eda.data$Family.size.numeric %in% c(1,3,5,6,7,8,11) , "Pclass.3",ifelse(eda.data$Family.size.numeric %in% c(4) , "Pclass.2", "Pclass.1")))

combined.data$famsize.pclass.relationship<-as.factor(ifelse(combined.data$Family.size.numeric %in% c(1,3,5,6,7,8,11) , "Pclass.3",ifelse(combined.data$Family.size.numeric %in% c(4) , "Pclass.2", "Pclass.1")))
```

-----
<font size="+2"><li>EDA Analysis 3: Fare</li></font>

```{r}
# Only 1 value has a missing value for Fare
length(which(is.na(combined.data$Fare)))
```

<p>We will impute the missing values of ***Fare*** with the median value</p>

```{r, echo=FALSE}
combined.data$Fare[which(is.na(combined.data$Fare))]<-median(combined.data$Fare, na.rm = TRUE)
```


```{r, echo=FALSE}
ggplot(data = eda.data, aes(x = Fare)) + geom_histogram() + ggtitle("Histogram on Fare")
```

<p>We will see the realtionship between ***Fare*** and other categorical varibales</p>
```{r, echo=FALSE}
ggplot(data=gather(eda.data, key = "Variable", value = "Value", -c(Age,Fare, Name, Ticket, Cabin)), aes(Value, Fare)) +facet_wrap(~ Variable, scale = "free_x") +geom_boxplot()
```

<p>There doesnt seem to be some insighful interactions between Fare and any predictor varibales</p>
<p>We will try to categorize the fare, it may be useful in our model. We will call this varibale ***Fare.factor***</p>

```{r, echo=FALSE}
a<-as.numeric(quantile(eda.data$Fare, c(0.25,0.50,0.75)))
b<-ifelse(eda.data$Fare>=0 & eda.data$Fare<=a[1], "low.fare",
          ifelse(eda.data$Fare>a[1] & eda.data$Fare<=a[2], "medium.fare",
                 ifelse(eda.data$Fare>a[2] & eda.data$Fare<=a[3], "high.fare", "very.high.fare")))
eda.data$Fare.factor<-as.factor(b)

a<-as.numeric(quantile(combined.data$Fare, c(0.25,0.50,0.75), na.rm = TRUE))
b<-ifelse(combined.data$Fare>=0 & combined.data$Fare<=a[1], "low.fare",
          ifelse(combined.data$Fare>a[1] & combined.data$Fare<=a[2], "medium.fare",
                 ifelse(combined.data$Fare>a[2] & combined.data$Fare<=a[3], "high.fare", "very.high.fare")))
combined.data$Fare.factor<-as.factor(b)
```

------
<font size="+2"><li>EDA Analysis 4: Name</li></font>
<p>We will extract the tittle in people's name so we can use them in our model. We will call this new factor ***Name.abr***. From the barplot, we see that ***Mr*** are the ones that died</p>

```{r, echo=FALSE}
Name.abr<-str_extract(string = eda.data$Name ,pattern = "(Mr.|Miss.|Mrs.|Master.|Dr.|Rev.|Col.|Mlle.|Major.|Ms.|Sir.|Capt.|Dona.|Don.|Lady|Mme)")
a<-ifelse(Name.abr %in% c("Mr.") , "Mr",
       ifelse(Name.abr %in% c("Mrs" , "Miss." , "Ms.") , "Mrs/Miss/Ms" ,
              ifelse(Name.abr %in% c("Master.") , "Master", "Others")))
eda.data$Name.abr<-as.factor(a)


Name.abr<-str_extract(string = combined.data$Name ,pattern = "(Mr.|Miss.|Mrs.|Master.|Dr.|Rev.|Col.|Mlle.|Major.|Ms.|Sir.|Capt.|Dona.|Don.|Lady|Mme)")
a<-ifelse(Name.abr %in% c("Mr.") , "Mr",
       ifelse(Name.abr %in% c("Mrs" , "Miss." , "Ms.") , "Mrs/Miss/Ms" ,
              ifelse(Name.abr %in% c("Master.") , "Master", "Others")))
combined.data$Name.abr<-as.factor(a)
```

```{r, echo=FALSE}
barplot(table(eda.data$Name.abr , eda.data$Survived), beside = TRUE, legend.text = TRUE, 
        main = "Survival based on name tittle")
```

<p>We will extract the last names of each passenger and call it ***Last.name***</p>
```{r, echo=FALSE}
first.name<-gsub(",.*$", "", eda.data$Name)
eda.data$Last.name<-as.factor(first.name)

first.name<-gsub(",.*$", "", combined.data$Name)
combined.data$Last.name<-as.factor(first.name)
```

-----

<font size="+2"><li>EDA Analysis 5: Family Size</li></font>

<p>From the kaggle description, we know that only female passengers survived, so we will create a custome varibale for that. If they are a ***female and if their age is less than 21.5*** we will say they are ***female and the survived***</p>
```{r, echo=FALSE}
eda.data$female.survived.kids<-as.factor(ifelse(eda.data$Age <21.5 & eda.data$Sex=="female" , "female.and.kid" , "female.and.not.kid"))

combined.data$female.survived.kids<-as.factor(ifelse(combined.data$Age <21.5 & combined.data$Sex=="female" , "female.and.kid" , "female.and.not.kid"))
```

<p>We will create a varibale for ***Is alone*** for only 1 passesnger when including family</p>
```{r, echo=FALSE}
eda.data$Is.alone<-as.factor(ifelse(eda.data$Family.size.numeric ==1, "is.alone", "not.alone"))
combined.data$Is.alone<-as.factor(ifelse(combined.data$Family.size.numeric ==1, "is.alone", "not.alone"))
```

-----
<font size="+2"><li>EDA Analysis 6: Cabin</li></font>
<p>Since there are alot of missing values, we will just impute those missing values with ***unknown***</p>
```{r, echo=FALSE}
eda.data$Cabin.impute<-substring(eda.data$Cabin,1,1)
eda.data$Cabin.impute[which(is.na(eda.data$Cabin.impute))]<- "unknown"
eda.data$Cabin.impute<-as.factor(eda.data$Cabin.impute)

combined.data$Cabin.impute<-substring(combined.data$Cabin,1,1)
combined.data$Cabin.impute[which(is.na(combined.data$Cabin.impute))]<- "unknown"
combined.data$Cabin.impute<-as.factor(combined.data$Cabin.impute)
```

----
<p>We will remove name out of our analysis since we don't need it anymore</p>
```{r, echo=FALSE}
eda.data<-eda.data %>% dplyr::select(-Name)
combined.data<-combined.data %>% dplyr::select(-Name)
```

-----
<font size="+3"><li>Feature Selection</li></font>
<p>We will use ***information gain*** as our source of varibale importance. This chart tells us what varibales will be very useful in our model. From the plot, we see that Ticket has the highest information, so we will still comtinue our analysis to see how we can use ***Ticket and Last.name***. Since these 2 varibales have alot of factors, we need another way to categorize them</p>
```{r, echo=FALSE}
eda.data.1<-eda.data %>% mutate_at(c("Survived", "Pclass", "Sex", "Embarked", "Ticket", "Cabin"), as.factor)

my.method<-"FSelectorRcpp_information.gain"
train.task.feature<-makeClassifTask(data = eda.data.1 , target = "Survived")
feature.importance<-generateFilterValuesData(train.task.feature, method = my.method)
plotFilterValues(feature.importance)
```

<font size="+3"><li>Modelling</li></font>
<p>We will split the data into train and test</p>
```{r, echo=FALSE}
train.data<-filter(combined.data[train.kaggle$PassengerId,])
test.data<-combined.data[-train.kaggle$PassengerId,]
nrow(train.data);nrow(test.data)
```

<p>We will create a ***xgboost model*** and fine tune and parameters to get a ***pseduo survival*** score</p>

```{r}
getParamSet("classif.xgboost")
```
<p>We will ***fine tune our XGBOOST*** model ***manually*** since that is much easier</p>

```{r, echo=FALSE}
set.seed(1234)
xgb<-makeLearner("classif.xgboost" , par.vals = list(eval_metric = 'error', 
                                                     eta = 0.4, max_depth = 4, min_child_weight = 0.1,
                                                     nthread = 1, nrounds = 50))

train.data.xgb<-train.data %>% dplyr::select(c(Name.abr, Sex, Survived, Pclass))
train.data.xgb <-mutate_at(train.data.xgb, .vars = vars(-Survived), .funs = as.numeric)

train.data.xgb.task<-makeClassifTask(data = train.data.xgb, target = "Survived")

kFold <- makeResampleDesc(method = "CV", iters = 5,stratify = TRUE)
kFoldCV <- resample(learner = xgb, task = train.data.xgb.task, resampling = kFold, measures = list(mmce, acc))

tuned.xgb<-train(xgb ,train.data.xgb.task )

test.data.xgb<-test.data %>% dplyr::select(c(Name.abr, Sex, Survived, Pclass))
test.data.xgb <-mutate_at(test.data.xgb, .vars = vars(-Survived), .funs = as.numeric)
a<-predict(tuned.xgb , newdata  = test.data.xgb)$data$response
```

<p>Our ***psudo survival*** has an accuracy of 0.79. We will treat this as a new factor and incorporate it into our analysis (dataframe)</p>

```{r, echo=FALSE}
test.data$xgb.survived<-a
train.data$xgb.survived<-train.data$Survived
combined.data<-mutate(bind_rows(train.data , test.data))
```

<p>We will now see if there is a relationship between ***Last name and our presudo survived***. We will group the values based on last name and if the mean of them is greater than 0.5, we wil call it 1, else 0 and we will call it ***Last.name.survived***</p>

```{r, echo=FALSE}
combined.data$xgb.survived<-as.numeric(as.character(combined.data$xgb.survived))
aa<-combined.data %>% group_by(Last.name) %>% summarise(Last.name.survived = 
                                                      ifelse(mean(xgb.survived)>0.5,1,0))

combined.data<-full_join(combined.data , aa)
head(combined.data, n=3)
```

<p>We will also capture the realtionship between our ***pesudo survial and ticket***</p>

```{r, echo=FALSE}
combined.data$Ticket.factor<-as.factor(substring(combined.data$Ticket,1,1))

aa<-combined.data %>% group_by(Ticket.factor) %>% summarise(Last.name.survived.ticket
                                                        =ifelse(mean(xgb.survived)>0.5,1,0))

combined.data<-full_join(combined.data , aa)
head(combined.data, n=3)
```


<p>We will create a categorical varibale that let's us know if a ***female*** survied (pseduo survived)</p>

```{r, echo=FALSE}
a<-ifelse(combined.data$Sex == "female" & combined.data$xgb.survived == 1, 1,0)
combined.data$female.and.survived<-as.factor(a)
```


```{r, echo=FALSE}
a<-ifelse(combined.data$Pclass==1 & combined.data$xgb.survived==1, "Most.likely.to.survive",
       ifelse(combined.data$Pclass==2 & combined.data$xgb.survived==1, "ok.likely.to.survive",
              ifelse(combined.data$Pclass==3 & combined.data$xgb.survived==1, "very.low.likely.to.survive", "dead")))

combined.data$pclass.survived.likely<-as.factor(a)
```


```{r, echo=FALSE}

table(combined.data$Embarked)
combined.data$Embarked[which(is.na(combined.data$Embarked))]<- "S"
combined.data$Embarked<-as.factor(combined.data$Embarked)
```


<p>We will resplit our data to see if the new features we created are more useful on our final model</p>

```{r, echo=FALSE}
combined.data$Last.name.survived<-as.factor(combined.data$Last.name.survived)
combined.data$Ticket<-as.factor(combined.data$Ticket)
combined.data$Last.name.survived.ticket<-as.factor(combined.data$Last.name.survived.ticket)
train.data<-filter(combined.data[train.kaggle$PassengerId,])
test.data<-combined.data[-train.kaggle$PassengerId,]
```


<p>The new varibale we have created ***Last.name.survived*** is an important feature based on the ***information gain criterion***</p>

```{r, echo=FALSE}
my.method<-"FSelectorRcpp_information.gain"
train.task.feature<-makeClassifTask(data = train.data , target = "Survived")
feature.importance<-generateFilterValuesData(train.task.feature, method = my.method)
plotFilterValues(feature.importance)
```

----
<font size="+3">Modelling</font>

```{r}
getParamSet("classif.randomForest")
```


```{r, echo=FALSE}
set.seed(1234)
forest <- makeLearner("classif.randomForest", par.vals = list(ntree=500, mtry=1, nodesize=5, maxnodes=50))


train.data.rf<-train.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass,Survived, Fare, Age))
train.data.rf.task<-makeClassifTask(data = train.data.rf, target = "Survived")

kFold <- makeResampleDesc(method = "RepCV", folds = 5, reps = 3, stratify = TRUE)
kFoldCV <- resample(learner = forest, task = train.data.rf.task, resampling = kFold, measures = list(mmce, acc))

tuned.forest<-train(forest , train.data.rf.task)

test.data.rf<-test.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass, Survived, Fare, Age))

tuned.forest.predcit.train.data<-predict(tuned.forest , newdata = train.data.rf)$data$response
tuned.forest.predcit.test.data<-predict(tuned.forest , newdata = test.data.rf)$data$response
```

<p>Our tuned forest has an ***CV*** accuracy of ~0.92</p>

```{r}
getParamSet("classif.xgboost")
```

```{r, echo=FALSE}
set.seed(1234)

xgb<-makeLearner("classif.xgboost" , par.vals = list(eval_metric = 'error', 
                                                     eta = 0.4,
                                                     nthread = 2, nrounds = 50, booster = 'gblinear'))

train.data.xgb<-train.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass,Survived, Fare, female.and.survived))
train.data.xgb <-mutate_at(train.data.xgb, .vars = vars(-Survived), .funs = as.numeric)

train.data.xgb.task<-makeClassifTask(data = train.data.xgb, target = "Survived")

kFold <- makeResampleDesc(method = "RepCV", folds = 5, reps = 3 , stratify = TRUE)
kFoldCV <- resample(learner = xgb, task = train.data.xgb.task, resampling = kFold, measures = list(mmce, acc))

tuned.xgb<-train(xgb ,train.data.xgb.task )

test.data.xgb<-test.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass,Survived, Fare, female.and.survived))
test.data.xgb <-mutate_at(test.data.xgb, .vars = vars(-Survived), .funs = as.numeric)

tuned.xgb.predict.train.data<-predict(tuned.xgb , newdata = train.data.xgb)$data$response
tuned.xgb.predict.test.data<-predict(tuned.xgb , newdata = test.data.xgb)$data$response
```

<p>Our tuned ***xgb*** has an ***CV*** accuracy of ~0.96</p>

```{r}
getParamSet("classif.kknn")
```

```{r, echo=FALSE}
set.seed(1234)

knn<-makeLearner("classif.kknn", par.vals = list(k=20))

train.data.knn<-train.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass,Survived, Fare, Age))
train.data.knn.task<-makeClassifTask(data = train.data.knn, target = "Survived")

kFold <- makeResampleDesc(method = "RepCV", folds = 5, reps = 3, stratify = TRUE)
kFoldCV <- resample(learner = knn, task = train.data.knn.task, resampling = kFold, measures = list(mmce, acc))

tuned.knn<-train(knn , train.data.knn.task)

test.data.knn<-test.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass, Survived, Fare, Age))

tuned.knn.predcit.train.data<-predict(tuned.knn , newdata = train.data.knn)$data$response
tuned.knn.predcit.test.data<-predict(tuned.knn , newdata = test.data.knn)$data$response
```

<p>Our tuned ***KNN*** has an ***CV*** accuracy of ~0.92</p>

```{r}
getParamSet("classif.svm")
```

```{r, echo=FALSE}
svm<-makeLearner("classif.svm", par.vals = list(cost = 25 , kernel = "radial", 
                                                type = "C-classification"))

train.data.svm<-train.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass,Survived, Fare, Age, female.and.survived))
train.data.svm.task<-makeClassifTask(data = train.data.svm, target = "Survived")

kFold <- makeResampleDesc(method = "RepCV", folds = 5, reps = 3, stratify = TRUE)
kFoldCV <- resample(learner = svm, task = train.data.svm.task, resampling = kFold, measures = list(mmce, acc))

tuned.svm<-train(svm , train.data.svm.task)

test.data.svm<-test.data %>% dplyr::select(c(Last.name.survived,Sex, Name.abr, Pclass, Survived, Fare, Age, female.and.survived))

tuned.svm.predcit.train.data<-predict(tuned.svm , newdata = train.data.svm)$data$response
tuned.svm.predcit.test.data<-predict(tuned.svm , newdata = test.data.svm)$data$response
```

<p>Our tuned ***SVM*** has an ***CV*** accuracy of ~0.96</p>

<font size="+3">Ensemble methods: Stacking</font>

<p>Our ***MEGA MODEL*** would be ***logistic regression***</p>

```{r, echo=FALSE}
train.stack.data<-data.frame(rf = tuned.forest.predcit.train.data ,
                             xgb =tuned.xgb.predict.train.data,
                             knn = tuned.knn.predcit.train.data,
                             svm = tuned.svm.predcit.train.data,
                             y =train.data$Survived )

train.stack.data<-mutate_at(train.stack.data ,.vars = vars(-y) ,as.numeric)
train.stack.data$y<-as.factor(train.stack.data$y)

test.stack.data<-data.frame(rf =tuned.forest.predcit.test.data,
                            xgb = tuned.xgb.predict.test.data,
                            knn = tuned.knn.predcit.test.data,
                            svm = tuned.svm.predcit.test.data
                              )

test.stack.data<-mutate_all(test.stack.data , as.numeric)

logistic.model<-glm(y ~ . , data = train.stack.data , family = binomial(link = "logit"))
summary(logistic.model)

final.data.accuracy<-rep(0, nrow(test.stack.data))
final.data.accuracy[which(predict(logistic.model , newdata = test.stack.data , type = "response")>0.5)]<-1
mean(real.values ==final.data.accuracy )

```

<p>Out final prediction for the test data is 0.8014354 (compared with kaggle submission; top 5%)</p>


```{r}
dput(final.data.accuracy)
```


















